{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfenriswulven\u001b[0m (\u001b[33mdtu_projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\wandb\\run-20231128_215921-915u3niv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dtu_projects/Normalising-Flow-DNN/runs/915u3niv' target=\"_blank\">still-brook-94</a></strong> to <a href='https://wandb.ai/dtu_projects/Normalising-Flow-DNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dtu_projects/Normalising-Flow-DNN' target=\"_blank\">https://wandb.ai/dtu_projects/Normalising-Flow-DNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dtu_projects/Normalising-Flow-DNN/runs/915u3niv' target=\"_blank\">https://wandb.ai/dtu_projects/Normalising-Flow-DNN/runs/915u3niv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train 6000 n_test 1000\n",
      "N: tensor([592, 671, 581, 608, 623, 514, 608, 651, 551, 601])\n",
      "Model saved\n",
      "Model: 0, Step: 500, Epoch: 6\tTrain Loss: 1.4504, Val Loss: 1.4726, Train Accuracy: 0.6969, Val Accuracy: 41.0000\n",
      "Model saved\n",
      "Model: 0, Step: 1000, Epoch: 11\tTrain Loss: 0.9693, Val Loss: 1.0033, Train Accuracy: 0.9044, Val Accuracy: 55.3125\n",
      "Model saved\n",
      "Model: 0, Step: 1500, Epoch: 16\tTrain Loss: 0.5260, Val Loss: 0.5844, Train Accuracy: 0.9644, Val Accuracy: 58.8750\n",
      "Model saved\n",
      "Model: 0, Step: 2000, Epoch: 22\tTrain Loss: 0.2257, Val Loss: 0.3376, Train Accuracy: 0.9898, Val Accuracy: 59.3125\n",
      "Model saved\n",
      "Model: 0, Step: 2500, Epoch: 27\tTrain Loss: 0.1053, Val Loss: 0.2190, Train Accuracy: 0.9978, Val Accuracy: 59.6250\n",
      "Model saved\n",
      "Model: 0, Step: 3000, Epoch: 32\tTrain Loss: 0.0568, Val Loss: 0.1731, Train Accuracy: 0.9998, Val Accuracy: 59.5625\n",
      "Model saved\n",
      "Model: 0, Step: 3500, Epoch: 38\tTrain Loss: 0.0324, Val Loss: 0.1606, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model saved\n",
      "Model: 0, Step: 4000, Epoch: 43\tTrain Loss: 0.0231, Val Loss: 0.1485, Train Accuracy: 1.0000, Val Accuracy: 59.8125\n",
      "Model saved\n",
      "Model: 0, Step: 4500, Epoch: 48\tTrain Loss: 0.0176, Val Loss: 0.1454, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model saved\n",
      "Model: 0, Step: 5000, Epoch: 54\tTrain Loss: 0.0142, Val Loss: 0.1437, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model saved\n",
      "Model: 0, Step: 5500, Epoch: 59\tTrain Loss: 0.0141, Val Loss: 0.1403, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model: 0, Step: 6000, Epoch: 64\tTrain Loss: 0.0142, Val Loss: 0.1403, Train Accuracy: 0.9998, Val Accuracy: 59.9375\n",
      "Model saved\n",
      "Model: 0, Step: 6500, Epoch: 70\tTrain Loss: 0.0143, Val Loss: 0.1397, Train Accuracy: 1.0000, Val Accuracy: 60.0625\n",
      "Model: 0, Step: 7000, Epoch: 75\tTrain Loss: 0.0122, Val Loss: 0.1398, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model saved\n",
      "Model: 0, Step: 7500, Epoch: 80\tTrain Loss: 0.0100, Val Loss: 0.1363, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model: 0, Step: 8000, Epoch: 86\tTrain Loss: 0.0094, Val Loss: 0.1522, Train Accuracy: 1.0000, Val Accuracy: 59.2500\n",
      "Model saved\n",
      "Model: 0, Step: 8500, Epoch: 91\tTrain Loss: 0.0043, Val Loss: 0.1145, Train Accuracy: 1.0000, Val Accuracy: 60.1875\n",
      "Model: 0, Step: 9000, Epoch: 96\tTrain Loss: 0.0025, Val Loss: 0.1187, Train Accuracy: 1.0000, Val Accuracy: 60.3125\n",
      "Model: 0, Step: 9500, Epoch: 102\tTrain Loss: 0.0014, Val Loss: 0.1205, Train Accuracy: 1.0000, Val Accuracy: 60.0000\n",
      "Model: 0, Step: 10000, Epoch: 107\tTrain Loss: 0.0010, Val Loss: 0.1222, Train Accuracy: 1.0000, Val Accuracy: 60.0625\n",
      "Model: 0, Step: 10500, Epoch: 112\tTrain Loss: 0.0007, Val Loss: 0.1212, Train Accuracy: 1.0000, Val Accuracy: 60.0625\n",
      "Model: 0, Step: 11000, Epoch: 118\tTrain Loss: 0.0005, Val Loss: 0.1234, Train Accuracy: 1.0000, Val Accuracy: 59.9375\n",
      "Model: 0, Step: 11500, Epoch: 123\tTrain Loss: 0.0005, Val Loss: 0.1268, Train Accuracy: 1.0000, Val Accuracy: 60.0000\n",
      "Model: 0, Step: 12000, Epoch: 128\tTrain Loss: 0.0004, Val Loss: 0.1255, Train Accuracy: 1.0000, Val Accuracy: 60.1250\n",
      "Model: 0, Step: 12500, Epoch: 133\tTrain Loss: 0.0004, Val Loss: 0.1298, Train Accuracy: 1.0000, Val Accuracy: 60.1250\n",
      "Model: 0, Step: 13000, Epoch: 139\tTrain Loss: 0.0003, Val Loss: 0.1283, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model: 0, Step: 13500, Epoch: 144\tTrain Loss: 0.0003, Val Loss: 0.1271, Train Accuracy: 1.0000, Val Accuracy: 59.9375\n",
      "Model: 0, Step: 14000, Epoch: 149\tTrain Loss: 0.0003, Val Loss: 0.1306, Train Accuracy: 1.0000, Val Accuracy: 60.0000\n",
      "Model: 0, Step: 14500, Epoch: 155\tTrain Loss: 0.0003, Val Loss: 0.1290, Train Accuracy: 1.0000, Val Accuracy: 60.0000\n",
      "Model: 0, Step: 15000, Epoch: 160\tTrain Loss: 0.0002, Val Loss: 0.1282, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model saved\n",
      "Model: 0, Step: 15500, Epoch: 165\tTrain Loss: 0.0013, Val Loss: 0.1096, Train Accuracy: 1.0000, Val Accuracy: 60.1250\n",
      "Model: 0, Step: 16000, Epoch: 171\tTrain Loss: 0.0004, Val Loss: 0.1118, Train Accuracy: 1.0000, Val Accuracy: 60.5000\n",
      "Model: 0, Step: 16500, Epoch: 176\tTrain Loss: 0.0003, Val Loss: 0.1169, Train Accuracy: 1.0000, Val Accuracy: 60.1875\n",
      "Model: 0, Step: 17000, Epoch: 181\tTrain Loss: 0.0002, Val Loss: 0.1196, Train Accuracy: 1.0000, Val Accuracy: 60.5000\n",
      "Model: 0, Step: 17500, Epoch: 187\tTrain Loss: 0.0002, Val Loss: 0.1260, Train Accuracy: 1.0000, Val Accuracy: 60.5000\n",
      "Model: 0, Step: 18000, Epoch: 192\tTrain Loss: 0.0001, Val Loss: 0.1233, Train Accuracy: 1.0000, Val Accuracy: 60.3750\n",
      "Model: 0, Step: 18500, Epoch: 197\tTrain Loss: 0.0001, Val Loss: 0.1222, Train Accuracy: 1.0000, Val Accuracy: 60.2500\n",
      "Finished training.\n",
      "Model saved\n",
      "Model: 1, Step: 500, Epoch: 6\tTrain Loss: 1.5408, Val Loss: 1.5759, Train Accuracy: 0.5974, Val Accuracy: 34.9375\n",
      "Model saved\n",
      "Model: 1, Step: 1000, Epoch: 11\tTrain Loss: 1.0855, Val Loss: 1.1263, Train Accuracy: 0.8438, Val Accuracy: 50.3750\n",
      "Model saved\n",
      "Model: 1, Step: 1500, Epoch: 16\tTrain Loss: 0.5923, Val Loss: 0.6647, Train Accuracy: 0.9582, Val Accuracy: 57.1250\n",
      "Model saved\n",
      "Model: 1, Step: 2000, Epoch: 22\tTrain Loss: 0.2415, Val Loss: 0.3781, Train Accuracy: 0.9874, Val Accuracy: 58.1875\n",
      "Model saved\n",
      "Model: 1, Step: 2500, Epoch: 27\tTrain Loss: 0.1125, Val Loss: 0.2326, Train Accuracy: 0.9975, Val Accuracy: 59.0000\n",
      "Model saved\n",
      "Model: 1, Step: 3000, Epoch: 32\tTrain Loss: 0.0590, Val Loss: 0.2015, Train Accuracy: 0.9996, Val Accuracy: 59.1875\n",
      "Model saved\n",
      "Model: 1, Step: 3500, Epoch: 38\tTrain Loss: 0.0348, Val Loss: 0.1763, Train Accuracy: 1.0000, Val Accuracy: 59.5625\n",
      "Model saved\n",
      "Model: 1, Step: 4000, Epoch: 43\tTrain Loss: 0.0221, Val Loss: 0.1702, Train Accuracy: 1.0000, Val Accuracy: 59.4375\n",
      "Model saved\n",
      "Model: 1, Step: 4500, Epoch: 48\tTrain Loss: 0.0172, Val Loss: 0.1595, Train Accuracy: 1.0000, Val Accuracy: 59.6250\n",
      "Model saved\n",
      "Model: 1, Step: 5000, Epoch: 54\tTrain Loss: 0.0142, Val Loss: 0.1571, Train Accuracy: 1.0000, Val Accuracy: 59.5625\n",
      "Model: 1, Step: 5500, Epoch: 59\tTrain Loss: 0.0138, Val Loss: 0.1595, Train Accuracy: 1.0000, Val Accuracy: 59.5000\n",
      "Model: 1, Step: 6000, Epoch: 64\tTrain Loss: 0.0140, Val Loss: 0.1585, Train Accuracy: 1.0000, Val Accuracy: 59.4375\n",
      "Model: 1, Step: 6500, Epoch: 70\tTrain Loss: 0.0137, Val Loss: 0.1577, Train Accuracy: 1.0000, Val Accuracy: 59.5000\n",
      "Model saved\n",
      "Model: 1, Step: 7000, Epoch: 75\tTrain Loss: 0.0119, Val Loss: 0.1540, Train Accuracy: 1.0000, Val Accuracy: 59.4375\n",
      "Model: 1, Step: 7500, Epoch: 80\tTrain Loss: 0.0097, Val Loss: 0.1590, Train Accuracy: 1.0000, Val Accuracy: 59.5625\n",
      "Model: 1, Step: 8000, Epoch: 86\tTrain Loss: 0.0062, Val Loss: 0.1590, Train Accuracy: 1.0000, Val Accuracy: 59.2500\n",
      "Model saved\n",
      "Model: 1, Step: 8500, Epoch: 91\tTrain Loss: 0.0098, Val Loss: 0.1357, Train Accuracy: 1.0000, Val Accuracy: 59.3125\n",
      "Model saved\n",
      "Model: 1, Step: 9000, Epoch: 96\tTrain Loss: 0.0028, Val Loss: 0.1303, Train Accuracy: 1.0000, Val Accuracy: 59.6250\n",
      "Model: 1, Step: 9500, Epoch: 102\tTrain Loss: 0.0013, Val Loss: 0.1327, Train Accuracy: 1.0000, Val Accuracy: 59.5000\n",
      "Model: 1, Step: 10000, Epoch: 107\tTrain Loss: 0.0010, Val Loss: 0.1428, Train Accuracy: 1.0000, Val Accuracy: 59.6250\n",
      "Model: 1, Step: 10500, Epoch: 112\tTrain Loss: 0.0008, Val Loss: 0.1438, Train Accuracy: 1.0000, Val Accuracy: 59.6875\n",
      "Model: 1, Step: 11000, Epoch: 118\tTrain Loss: 0.0008, Val Loss: 0.1408, Train Accuracy: 1.0000, Val Accuracy: 59.9375\n",
      "Model: 1, Step: 11500, Epoch: 123\tTrain Loss: 0.0005, Val Loss: 0.1450, Train Accuracy: 1.0000, Val Accuracy: 59.8750\n",
      "Model: 1, Step: 12000, Epoch: 128\tTrain Loss: 0.0004, Val Loss: 0.1416, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model: 1, Step: 12500, Epoch: 133\tTrain Loss: 0.0004, Val Loss: 0.1491, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model: 1, Step: 13000, Epoch: 139\tTrain Loss: 0.0003, Val Loss: 0.1485, Train Accuracy: 1.0000, Val Accuracy: 59.8125\n",
      "Model: 1, Step: 13500, Epoch: 144\tTrain Loss: 0.0003, Val Loss: 0.1448, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model: 1, Step: 14000, Epoch: 149\tTrain Loss: 0.0004, Val Loss: 0.1523, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model: 1, Step: 14500, Epoch: 155\tTrain Loss: 0.0003, Val Loss: 0.1494, Train Accuracy: 1.0000, Val Accuracy: 59.5000\n",
      "Model: 1, Step: 15000, Epoch: 160\tTrain Loss: 0.0003, Val Loss: 0.1501, Train Accuracy: 1.0000, Val Accuracy: 59.6250\n",
      "Model: 1, Step: 15500, Epoch: 165\tTrain Loss: 0.0007, Val Loss: 0.2625, Train Accuracy: 1.0000, Val Accuracy: 58.0625\n",
      "Model saved\n",
      "Model: 1, Step: 16000, Epoch: 171\tTrain Loss: 0.0027, Val Loss: 0.1262, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model saved\n",
      "Model: 1, Step: 16500, Epoch: 176\tTrain Loss: 0.0007, Val Loss: 0.1228, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n",
      "Model saved\n",
      "Model: 1, Step: 17000, Epoch: 181\tTrain Loss: 0.0005, Val Loss: 0.1227, Train Accuracy: 1.0000, Val Accuracy: 59.7500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=337'>338</a>\u001b[0m training_scheduler \u001b[39m=\u001b[39m lr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimiser, T_max\u001b[39m=\u001b[39mannealing_interval, eta_min\u001b[39m=\u001b[39mmin_lr, last_epoch\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=338'>339</a>\u001b[0m \u001b[39m#training_scheduler= torch.optim.lr_scheduler.StepLR(optimiser, step_size=5, gamma=0.1)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=339'>340</a>\u001b[0m \u001b[39m#training_scheduler= ExponentialLR(optimizer=default_optimizer, gamma=0.98)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=341'>342</a>\u001b[0m train_losses, val_losses, train_accuracies, val_accuracies, all_train_losses \u001b[39m=\u001b[39m train(model, optimiser, train_loader, test_loader, num_epochs, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=342'>343</a>\u001b[0m                              validation_every_steps, early_stop_delta, early_stop_patience, warmup_scheduler, training_scheduler, warmup_steps, ensemble_number)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=343'>344</a>\u001b[0m ensemble_number \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=239'>240</a>\u001b[0m train_losses_batches, train_accuracies_batches \u001b[39m=\u001b[39m [], []\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=240'>241</a>\u001b[0m \u001b[39m#batches_counter = 0\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=242'>243</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_index, (X_train, y_train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=243'>244</a>\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mto(device), y_train\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m     \u001b[39m# batches_counter += 1\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W0sZmlsZQ%3D%3D?line=245'>246</a>\u001b[0m     \u001b[39m# Forward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 295\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:167\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    166\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[1;32m--> 167\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], \u001b[39mlen\u001b[39;49m(pic\u001b[39m.\u001b[39;49mgetbands()))\n\u001b[0;32m    168\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    169\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.nn.utils as utils\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from typing import Tuple, List, Callable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import utils as vutils\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import gaussian_kde\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "import os \n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Coupling_mnist_plots.ipynb'\n",
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "############ HYPERPARAMETERS ################\n",
    "#lr = 0.00005\n",
    "training_lr = 0.0005 # start of training (end of warmup ) #Note: High LR create NaNs and Inf \n",
    "start_lr = 1e-9 # start of warmup\n",
    "min_lr = 1e-7 # during cosine annealing\n",
    "num_epochs = 200 # flere epochs maybe 12000\n",
    "warmup_steps= 2000\n",
    "validation_every_steps = 500 # is actually every epoch in training loop!!\n",
    "#validation_every_epochs = 1\n",
    "weight_decay = 5e-7  # L2 regularization strength to prevent overfitting in Adam or AdamW \n",
    "batch_size = 64\n",
    "early_stop_delta = 0.001 #in procent this is 0.1% \n",
    "early_stop_patience = 25 # so after 20 validations without improvement, stop training\n",
    "reg = 1e-5 # entropy regularisation\n",
    "annealing_interval = 200 # Every 10 epochs, anneal LR (warm restart)\n",
    "\n",
    "num_ensemble_models = 5 # ændre til 10  # Define the number of models in the ensemble\n",
    "num_classes = 10\n",
    "latent_dim = 6 # Change to 4 or 6    # the encoder outputs 2D latent space\n",
    "# data_dim = 6 # the encoder outputs 2D latent space\n",
    "# in_dim= data_dim // 2 # since we split the data\n",
    "# out_dim= data_dim // 2\n",
    "# num_params = 2 # s and t\n",
    "# num_hidden = 3 # number of hidden layers\n",
    "# hidden_dim = 64 # neurons in hidden layers\n",
    "\n",
    "wandb.init(\n",
    "    project='Normalising-Flow-DNN',\n",
    "    config={\n",
    "        'architecture': 'Ensemble',\n",
    "        'dataset': 'MNIST',\n",
    "        'training_lr': training_lr,\n",
    "        'start_lr': start_lr,\n",
    "        'min_lr': min_lr,\n",
    "        'num_epochs': num_epochs,\n",
    "        'warmup_steps': warmup_steps,\n",
    "        'validation_every_steps': validation_every_steps,\n",
    "        'weight_decay': weight_decay,\n",
    "        'batch_size': batch_size,\n",
    "        'early_stop_delta': early_stop_delta,\n",
    "        'early_stop_patience': early_stop_patience,\n",
    "        'reg': reg,\n",
    "        'annealing_interval': annealing_interval,\n",
    "        'num_ensemble_models': num_ensemble_models,\n",
    "        'num_classes': num_classes,\n",
    "        'latent_dim': latent_dim,\n",
    "    }\n",
    "    #name='run_name',\n",
    "    #tags=['experiment1', ''],\n",
    "    #notes='Trying out a new architecture',\n",
    "    #dir='/path/to/log/files',\n",
    "    ##entity='my_team',\n",
    "    #group='experiment_group',\n",
    "    #job_type='train'\n",
    ")\n",
    "\n",
    "\n",
    "############ CLASSES ################\n",
    "# Define the Normalising Flow model template\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        )\n",
    "\n",
    "        self.linear_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        #print(\"Shape after conv_block:\", x.shape) #64batchsize x 64channels x 1height x 1width\n",
    "        #x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.linear_block(x)\n",
    "        return x\n",
    "\n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.cnn = CNN(latent_dim)\n",
    "        self.fc = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "class GradualWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, start_lr, end_lr, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.start_lr = start_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.lr_increment = (end_lr - start_lr) / warmup_steps\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            lr = self.start_lr + self.last_epoch * self.lr_increment\n",
    "            return [lr for _ in self.base_lrs]\n",
    "        return self.base_lrs\n",
    "    \n",
    "############ LOAD MNIST DATASET ################\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "batch_size = 64 # standard value\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "#subset_percentage = 0.1\n",
    "#num_samples = int(len(train_dataset) * subset_percentage)\n",
    "#print(\"Number of samples:\", num_samples)\n",
    "num_train = int(len(train_dataset) * 0.1)\n",
    "num_test = int(len(test_dataset) * 0.1)\n",
    "print(\"n_train\", num_train, \"n_test\", num_test)\n",
    "train_subset = Subset(train_dataset, range(num_train))\n",
    "test_subset = Subset(test_dataset, range(num_test)) \n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Get ground-truth label counts N_c\n",
    "# Dictionary with class names from indexes.\n",
    "classes = {index: name for name, index in train_dataset.class_to_idx.items()}\n",
    "\n",
    "# Initialise dictionary to store the counts for each class using class indexes\n",
    "N = {index: 0 for index in range(len(classes))}\n",
    "# Count the occurrences of each class\n",
    "#for _, target in train_dataset:\n",
    "for _, target in train_subset:\n",
    "    N[target] += 1\n",
    "N = torch.tensor([N[index] for index in range(len(classes))])\n",
    "print(\"N:\", N)\n",
    "\n",
    "#y_train = torch.tensor([target for _, target in train_dataset])\n",
    "y_train = torch.tensor([target for _, target in train_subset])\n",
    "\n",
    "############# FUNCTION ##################\n",
    "def image_show(img):\n",
    "    img = img.detach().cpu()\n",
    "    img = img / 2 + 0.5   #Unnormalise\n",
    "    with sns.axes_style(\"white\"):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img.permute((1, 2, 0)).numpy())\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def init_weights(model):\n",
    "    if isinstance(model, nn.Linear):\n",
    "        nn.init.xavier_normal_(model.weight)\n",
    "        nn.init.zeros_(model.bias) \n",
    "\n",
    "def accuracy(y_train, preds):\n",
    "    accuracy = accuracy_score(y_train.cpu().numpy(), preds.cpu().numpy())\n",
    "    return accuracy\n",
    "\n",
    "############# INSTANTIATE MODEL ##################\n",
    "ensemble_models = [Ensemble(latent_dim, num_classes).to(device) for _ in range(num_ensemble_models)]\n",
    "optimisers = [optim.AdamW(model.parameters(), lr=training_lr, weight_decay=weight_decay) for model in ensemble_models]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_steps_per_epoch = len(train_loader)  # Total batches (steps) per epoch\n",
    "warmup_epochs = math.ceil(warmup_steps / total_steps_per_epoch)  # Total warmup epochs\n",
    "\n",
    "############## TRAINING ######################\n",
    "# Trains one model in the ensemble\n",
    "ensemble_number = 0\n",
    "def train(model, optimiser, train_loader, test_loader, num_epochs, validation_every_steps, \n",
    "          early_stop_delta, early_stop_patience, warmup_scheduler, training_scheduler, warmup_steps, ensemble_number):\n",
    "    model.train()\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
    "    all_train_losses = []\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    step = 0 # how many batches we have trained on (each batch is 64 samples) #9000 training samples / 64 batch size = 140 batches per epoch\n",
    "    counter = 0 # for early stopping \n",
    "    early_stopping = False\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    for epoch in range(num_epochs): #epoch is one forward pass through the entire training set\n",
    "        train_losses_batches, train_accuracies_batches = [], []\n",
    "        #batches_counter = 0\n",
    "\n",
    "        for batch_index, (X_train, y_train) in enumerate(train_loader):\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            # batches_counter += 1\n",
    "            # Forward pass\n",
    "            output = model(X_train)\n",
    "            loss = criterion(output, y_train) #CrossEntropy loss\n",
    "            # Perform one training step\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimiser.step()\n",
    "            if step < warmup_steps:\n",
    "                warmup_scheduler.step()         \n",
    "            step += 1\n",
    "            #train_losses.append(loss.item())\n",
    "            # Compute training accuracy and loss for this batch\n",
    "            with torch.no_grad():\n",
    "                preds = torch.argmax(output, dim=1)\n",
    "                train_accuracy_batch = accuracy(y_train, preds)\n",
    "                train_accuracies_batches.append(train_accuracy_batch)\n",
    "                train_losses_batches.append(loss.item())\n",
    "                all_train_losses.append(loss.item())\n",
    "                current_lr = optimiser.param_groups[0]['lr']\n",
    "                wandb.log({\"batch_train_losses\": loss.item(), \"batch_train_accuracy\": \n",
    "                           train_accuracy_batch, \"step\": step, \"learning_rate\": current_lr, \"epoch\": epoch})\n",
    "                \n",
    "            if step % validation_every_steps == 0:\n",
    "                train_loss = np.mean(train_losses_batches)\n",
    "                train_losses.append(train_loss)\n",
    "                train_accuracy = np.mean(train_accuracies_batches)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_accuracy, \"step\": step})\n",
    "\n",
    "                val_losses_batches = []\n",
    "                #val_accuracies_batches = []\n",
    "                val_correct = []\n",
    "                model.eval()\n",
    "                with torch.no_grad():   \n",
    "                    for batch_index, (X_test, y_test) in enumerate(test_loader):\n",
    "                        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                        # Evaluation Forward pass\n",
    "                        output = model(X_test)\n",
    "                        loss = criterion(output, y_test) #CrossEntropy loss\n",
    "                        preds = torch.argmax(output, dim=1)\n",
    "                        correct_batch = (preds == y_test).sum().item()\n",
    "                        val_correct.append(correct_batch)\n",
    "                        val_losses_batches.append(loss.item())\n",
    "\n",
    "                val_accuracy = sum(val_correct) / len(y_test) # or use len(test_dataset)\n",
    "                #Multiply by len(test_dataset) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "                val_accuracies.append(val_accuracy)\n",
    "                val_loss = np.mean(val_losses_batches) \n",
    "                val_losses.append(val_loss)\n",
    "                wandb.log({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy, \"step\": step})\n",
    "                model.train()\n",
    "\n",
    "                if val_losses[-1] < -1.:\n",
    "                    print(\"Unstable training\")\n",
    "                    break\n",
    "                if np.isnan(val_losses[-1]):\n",
    "                    print('Detected NaN Loss')\n",
    "                    break\n",
    "                # If val_loss is the best so far, save the model state_dict and reset the early stopping counter\n",
    "                if val_losses[-1] < best_val_loss:\n",
    "                    best_val_loss = val_losses[-1]\n",
    "                    counter = 0\n",
    "                    best_model = model.state_dict()\n",
    "                    torch.save({'epoch': epoch, 'model_state_dict': best_model, 'loss': best_val_loss}, f'best_model_ensemble{ensemble_number}.pth')\n",
    "                    print('Model saved')\n",
    "\n",
    "                # Early stopping - if val_loss is not improving (plus a delta e-4 as buffer) then start counter\n",
    "                # after patience of a certain number of validations, then stop training\n",
    "                elif val_losses[-1] > (best_val_loss + early_stop_delta):\n",
    "                    counter += 1\n",
    "                    if counter >= early_stop_patience:\n",
    "                        #print(\"Early stopping\")\n",
    "                        early_stopping = True\n",
    "                        break\n",
    "                \n",
    "                print(f\"Model: {ensemble_number}, Step: {step}, Epoch: {epoch+1}\\tTrain Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}\")\n",
    "                #### Lave plots med meshgrid f-funktion af normalising flow undervejs for at se ændringen\n",
    "        \n",
    "        # Update training scheduler (annealing LR)\n",
    "        if epoch >= warmup_epochs:\n",
    "                training_scheduler.step()\n",
    "\n",
    "        if early_stopping: # if true\n",
    "            print(\"Early stopping triggered. Exiting training.\")\n",
    "            break  # Break out of the outer loop\n",
    "    print(\"Finished training.\")\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, all_train_losses #,model\n",
    "\n",
    "# Train each model in the ensemble with warmup and annealing'\n",
    "for model, optimiser in zip(ensemble_models, optimisers):\n",
    "    warmup_scheduler = GradualWarmupScheduler(optimiser, warmup_steps=warmup_steps, start_lr=start_lr, end_lr=training_lr)\n",
    "    training_scheduler = lr_scheduler.CosineAnnealingLR(optimiser, T_max=annealing_interval, eta_min=min_lr, last_epoch=-1)\n",
    "    #training_scheduler= torch.optim.lr_scheduler.StepLR(optimiser, step_size=5, gamma=0.1)\n",
    "    #training_scheduler= ExponentialLR(optimizer=default_optimizer, gamma=0.98)\n",
    "    \n",
    "    train_losses, val_losses, train_accuracies, val_accuracies, all_train_losses = train(model, optimiser, train_loader, test_loader, num_epochs, \n",
    "                                 validation_every_steps, early_stop_delta, early_stop_patience, warmup_scheduler, training_scheduler, warmup_steps, ensemble_number)\n",
    "    ensemble_number += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Evaluate Ensemble\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ensemble_accuracy \u001b[39m=\u001b[39m evaluate_ensemble(ensemble_models, test_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEnsemble Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mensemble_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m############ PLOTS ################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Plot loss of training and validation\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ensemble_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([model(data) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m ensemble_models])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ensemble_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(ensemble_outputs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     pred \u001b[39m=\u001b[39m ensemble_output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ensemble_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([model(data) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m ensemble_models])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     ensemble_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(ensemble_outputs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     pred \u001b[39m=\u001b[39m ensemble_output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1210\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1212\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(features)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\ollie\\OneDrive - Danmarks Tekniske Universitet\\Uni\\Bachelor Projekt\\Normalising-Flow-DNN\\1ensemble_mnist.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m#print(\"Shape after conv_block:\", x.shape) #64batchsize x 64channels x 1height x 1width\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39m#x = x.view(x.size(0), -1) # flatten\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_block(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ollie/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Uni/Bachelor%20Projekt/Normalising-Flow-DNN/1ensemble_mnist.ipynb#W1sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_ensemble(ensemble_models, test_loader):\n",
    "    for model in ensemble_models:\n",
    "        model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            ensemble_outputs = torch.stack([model(data) for model in ensemble_models])\n",
    "            ensemble_output = torch.mean(ensemble_outputs, dim=0)\n",
    "            pred = ensemble_output.argmax(dim=1, keepdim=True)\n",
    "            total_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = total_correct / len(test_loader.dataset)\n",
    "    return accuracy\n",
    "# Evaluate Ensemble\n",
    "ensemble_accuracy = evaluate_ensemble(ensemble_models, test_loader)\n",
    "print(f'Ensemble Accuracy: {ensemble_accuracy:.4f}')\n",
    "\n",
    "\n",
    "############ PLOTS ################\n",
    "# Plot loss of training and validation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(train_losses, label='Train Loss')\n",
    "axes[0].plot(val_losses, label='Validation Loss')\n",
    "axes[0].set_xlabel('Validation Epochs')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Train and Validation Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot accuracies of training and validation\n",
    "axes[1].plot(train_accuracies, label='Train Accuracy')\n",
    "axes[1].plot(val_accuracies, label='Validation Accuracy')\n",
    "axes[1].set_xlabel('Steps')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Train and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots_mnist/training_loss_acc.png', bbox_inches='tight')\n",
    "\n",
    "# plot all_train_losses\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(all_train_losses,  '.',label='Train Loss', alpha=0.3)\n",
    "#plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()\n",
    "plt.savefig('plots_mnist/training_all_losses_acc.png', bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
