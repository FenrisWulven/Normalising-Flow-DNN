{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m                 df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n\u001b[0;32m     40\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m---> 41\u001b[0m                     results_dict[flow][metric]\u001b[38;5;241m.\u001b[39mloc[reg_value, lr_value] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# print how many csv files were processed\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(file_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics and hyperparameters\n",
    "    #accuracy,brier_score,confidence_APR_aleatoric,confidence_APR_epistemic,confidence_AUROC_aleatoric,confidence_AUROC_epistemic,\n",
    "    # entropy_aleatoric,entropy_epistemic,ood_detection_APR_aleatoric_FashionMNIST,ood_detection_APR_epistemic_FashionMNIST,\n",
    "    # ood_detection_AUROC_aleatoric_FashionMNIST,ood_detection_AUROC_epistemic_FashionMNIST,entropy_aleatoric_FashionMNIST,\n",
    "    # entropy_epistemic_FashionMNIST,ood_detection_APR_aleatoric_KMNIST,ood_detection_APR_epistemic_KMNIST,\n",
    "    # ood_detection_AUROC_aleatoric_KMNIST,ood_detection_AUROC_epistemic_KMNIST,entropy_aleatoric_KMNIST,entropy_epistemic_KMNIST\n",
    "metrics = ['accuracy', 'brier_score', 'confidence_APR_aleatoric', 'confidence_APR_epistemic', 'ood_detection_APR_aleatoric_FashionMNIST', \n",
    "           'ood_detection_APR_epistemic_FashionMNIST', 'ood_detection_APR_aleatoric_KMNIST', 'ood_detection_APR_epistemic_KMNIST']\n",
    "flows = [6] #['4', '6', '8', '10', '20']\n",
    "learning_rates = ['LR0.001', 'LR0.0001', 'LR1e-05']\n",
    "regularization_strengths = ['Reg0', 'Reg0.0001', 'Reg1e-05', ]\n",
    "#regularization_strengths = ['Reg0', 'Reg0.001', 'Reg0.0001', 'Reg1e-05', 'Reg5e-05', 'Reg5e-06']\n",
    "\n",
    "# Initialize dictionary for results\n",
    "results_dict = {flow: {metric: pd.DataFrame(index=regularization_strengths, columns=learning_rates, data=0.0) for metric in metrics} for flow in flows}\n",
    "\n",
    "# Directory with CSV files\n",
    "path = '.'\n",
    "\n",
    "# Process CSV files\n",
    "file_names = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.csv')]\n",
    "for flow in flows:\n",
    "    for file_name in file_names:\n",
    "        if f'Flows{flow}' in file_name:\n",
    "            # Extract LR and Reg from file name\n",
    "            parts = file_name.split('_')\n",
    "            lr_part = [part for part in parts if part.startswith('LR')][0]\n",
    "            reg_part = [part for part in parts if part.startswith('Reg')][0]\n",
    "            lr_value = 'LR' + lr_part[2:]\n",
    "            reg_value = 'Reg' + reg_part[3:]\n",
    "\n",
    "            # Read data and update the corresponding DataFrame\n",
    "            if lr_value in learning_rates and reg_value in regularization_strengths:\n",
    "                df = pd.read_csv(file_name)\n",
    "                for metric in metrics:\n",
    "                    results_dict[flow][metric].loc[reg_value, lr_value] = df[metric].item()\n",
    "\n",
    "# print how many csv files were processed\n",
    "print(f\"Processed {len(file_names)} files\")\n",
    "# print the \n",
    "\n",
    "# Visualization\n",
    "for flow, metrics_dict in results_dict.items():\n",
    "    # only show flow 6\n",
    "    # if flow != '':\n",
    "    #     continue\n",
    "    for metric, df in metrics_dict.items():\n",
    "        latex_table = df.to_latex(float_format=\"%.6f\", header=True, bold_rows=True)\n",
    "        latex_table = latex_table.replace(\"\\\\toprule\", f\"\\\\toprule\\n{{\\\\textbf{{{metric.title()}}}}} & \\\\multicolumn{{3}}{{c}}{{\\\\textbf{{Learning Rates}}}} \\\\\\\\\")\n",
    "        #\n",
    "        # print(f\"Results for Flow {flow}, Metric: {metric}\")\n",
    "        print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m             df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n\u001b[0;32m     27\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m---> 28\u001b[0m                 results_df\u001b[38;5;241m.\u001b[39mloc[model, metric] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# read the data and update the dataframe\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Convert the DataFrame to a LaTeX table\u001b[39;00m\n\u001b[0;32m     32\u001b[0m latex_table \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mto_latex(float_format\u001b[38;5;241m=\u001b[39mformat_float, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bold_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, na_rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Metrics and hyperparameters\n",
    "#metrics = ['accuracy', 'brier_score', 'confidence_APR_aleatoric', 'confidence_APR_epistemic', 'ood_detection_APR_aleatoric_SVHN', 'ood_detection_APR_epistemic_SVHN']\n",
    "metrics = ['accuracy', 'brier_score', 'confidence_APR_aleatoric', 'confidence_APR_epistemic', 'ood_detection_APR_aleatoric_FashionMNIST', \n",
    "           'ood_detection_APR_epistemic_FashionMNIST', 'ood_detection_APR_aleatoric_KMNIST', 'ood_detection_APR_epistemic_KMNIST']\n",
    "models = ['Ensemble', 'PostNet']\n",
    "# Initialize a DataFrame for results\n",
    "results_df = pd.DataFrame(index=models, columns=metrics)\n",
    "\n",
    "# Directory with CSV files\n",
    "path = '.'  # Update this if your CSV files are in a different directory\n",
    "\n",
    "# Function to format floats\n",
    "def format_float(x):\n",
    "    return f\"{x:.6f}\"\n",
    "\n",
    "# Process CSV files\n",
    "file_names = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.csv')]\n",
    "for file_name in file_names:\n",
    "    # Check if the model name of csv is in the list of models\n",
    "    for model in models:\n",
    "        if model in file_name:\n",
    "            # Read data and update the corresponding DataFrame\n",
    "            df = pd.read_csv(file_name)\n",
    "            for metric in metrics:\n",
    "                results_df.loc[model, metric] = df[metric].item()\n",
    "    # read the data and update the dataframe\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table\n",
    "latex_table = results_df.to_latex(float_format=format_float, header=True, bold_rows=True, na_rep='N/A')\n",
    "print(latex_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : \t 99.08 \t 97.51\n",
      "brier_score : \t 2.91 \t 5.18\n",
      "confidence_APR_aleatoric : \t 99.98 \t 99.83\n",
      "confidence_APR_epistemic : \t 99.98 \t 99.54\n",
      "ood_detection_APR_aleatoric_FashionMNIST : \t 99.2 \t 95.3\n",
      "ood_detection_APR_epistemic_FashionMNIST : \t 70.73 \t 89.59\n",
      "ood_detection_APR_aleatoric_KMNIST : \t 99.57 \t 97.59\n",
      "ood_detection_APR_epistemic_KMNIST : \t 70.85 \t 96.59\n"
     ]
    }
   ],
   "source": [
    "# Load the csv file\n",
    "df1 = pd.read_csv('csvEnsemble_LR0.001_Warm1000_Epoch500_Wdecay1e-05.csv')\n",
    "df2 = pd.read_csv('csvPostNet_Reg1e-05_LR0.001_Flows6_Warm1000_Epoch300_Wdecay1e-05_HidD64_hLay3_LD10.csv')\n",
    "\n",
    "# Print these metrics mulitplied by 100 and rounded to 2 decimal places\n",
    "metrics = ['accuracy', 'brier_score', 'confidence_APR_aleatoric', 'confidence_APR_epistemic', 'ood_detection_APR_aleatoric_FashionMNIST', \n",
    "           'ood_detection_APR_epistemic_FashionMNIST', 'ood_detection_APR_aleatoric_KMNIST', 'ood_detection_APR_epistemic_KMNIST']\n",
    "for metric in metrics:\n",
    "    print(metric, \": \\t\",round(df1[metric].item()*100, 2), \"\\t\", round(df2[metric].item()*100, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     plot_uncertainty(aleatoric_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maleatoric\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m     plot_uncertainty(epistemic_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepistemic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m \u001b[43mplot_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentropy_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 32\u001b[0m, in \u001b[0;36mplot_entropy\u001b[1;34m(entropy_data, dataset_name, model_name, n_bins)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_entropy\u001b[39m(entropy_data, dataset_name, model_name, n_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m     aleatoric_data \u001b[38;5;241m=\u001b[39m {label: values \u001b[38;5;28;01mfor\u001b[39;00m label, values \u001b[38;5;129;01min\u001b[39;00m \u001b[43mentropy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maleatoric\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m label}\n\u001b[0;32m     33\u001b[0m     epistemic_data \u001b[38;5;241m=\u001b[39m {label: values \u001b[38;5;28;01mfor\u001b[39;00m label, values \u001b[38;5;129;01min\u001b[39;00m entropy_data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepistemic\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m label}\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_uncertainty\u001b[39m(data, uncertainty_type):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# entropy_data_df = pd.DataFrame([entropy_data])\n",
    "# csv_save_path = os.path.join(plots_dir, dataset_name, 'entropy_csv' + ensemble_name + '.csv')\n",
    "# os.makedirs(os.path.dirname(csv_save_path), exist_ok=True)\n",
    "# entropy_data_df.to_csv(csv_save_path, index=False)\n",
    "\n",
    "# entropy_aleatoric_MNIST,entropy_epistemic_MNIST,entropy_aleatoric_FashionMNIST,entropy_epistemic_FashionMNIST,entropy_aleatoric_KMNIST,entropy_epistemic_KMNIST\n",
    "\n",
    "\n",
    "csv_file = 'entropy_csvEnsemble_LR0.001_Warm1000_Epoch500_Wdecay1e-05.csv'\n",
    "# i want it as a dictionary with arrayss\n",
    "entropy_data = pd.read_csv(csv_file)\n",
    "# remove the string tag\n",
    "entropy_data = entropy_data.replace(to_replace=r'\\[|\\]', value='', regex=True)\n",
    "#entropy_data = entropy_data.to_dict('list')\n",
    "\n",
    "\n",
    "#Plot the epistemic and aleatoric uncertainty for the ensemble model\n",
    "dataset_name = 'MNIST'\n",
    "ensemble_name = 'Ensemble'\n",
    "\n",
    "def plot_entropy(entropy_data, dataset_name, model_name, n_bins=30):\n",
    "    aleatoric_data = {label: values for label, values in entropy_data.items() if 'aleatoric' in label}\n",
    "    epistemic_data = {label: values for label, values in entropy_data.items() if 'epistemic' in label}\n",
    "\n",
    "    def plot_uncertainty(data, uncertainty_type):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for label, values in data.items():\n",
    "            plt.hist(values, bins=n_bins, alpha=0.5, label=f'{label.replace(\"_\", \" \").capitalize()}') #label=f'{label.capitalize()} Entropy')\n",
    "        \n",
    "        plt.xlabel('Entropy')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title(f'{uncertainty_type.capitalize()} Uncertainty Histogram for {dataset_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        #plot_path = os.path.join(plots_dir, dataset_name, uncertainty_type + '_combined_entropy_' + model_name + '.png')\n",
    "        #plt.savefig(plot_path, bbox_inches='tight')\n",
    "        plt.show()  \n",
    "    \n",
    "    plot_uncertainty(aleatoric_data, 'aleatoric')\n",
    "    plot_uncertainty(epistemic_data, 'epistemic')\n",
    "\n",
    "plot_entropy(entropy_data, dataset_name, ensemble_name, n_bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
